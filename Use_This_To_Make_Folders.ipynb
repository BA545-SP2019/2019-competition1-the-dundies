{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition 1 - Write Up #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question & Goal ####\n",
    "\n",
    "What are the determinants of the IPO underpricing phenomena? It is our job as a group to understand and identify the underlying determinants that factor into IPO underpricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding ###\n",
    "\n",
    "According to Investopedia.com, Underpricing is the listing of an intial public offering (IPO) below its market value. When the offer price of the stock is lower than the price of the first trade, the stock is considered to be underpriced. This will only last for a short amount of time, as the demand of the stock is going to drive it back up to its value.\n",
    "\n",
    "From a company standpoint, they wish to have the intial public offering as high as possible, which in turn raises the most capital. The quantitative factors that go into an initial public offering are all financial analysis reports from the company itself. Before the IPO, the company will be analyzed by its sales, expenses, earnings, and cash flow. Furthermore, a company's earnings and expected earnings growth are the biggest factors in the IPO. Marketability in a specific industry and the general market also can drive an IPO up or down.\n",
    "\n",
    "Once the investment bankers or IPO underwriters determine the IPO price of the company's stock, the day before the stock is offered publically, the company will market the IPO to potential investors. For historical purposes, IPOs are viewed as risky investments because of the lack of historical data that is collected on them. The less liquidity that the stock/company has and predicatble IPO shares are going to be, the more likely they are going to be underprices to compensate for assumed risk. Company's also underprice their IPO to entice more investors to buy stocks to raise more capital.\n",
    "\n",
    "With all of this information about intial public offerings, is there a few determinants that can be identified as to why the phenomenon of underpricing exists? The dataset that we have been provided provide information about companies and information regarding their IPO, such as IPO Offering, IPO Characteristics, Textual Characterisitics, Sentiment Characteristics, Target Variables, Control Variables, and IPO Identifiers.\n",
    "\n",
    "The variables that have been provided are listed below:\n",
    "\n",
    " - P(IPO) - Offer Price\n",
    " - P(H) - Price Range Higher Bound\n",
    " - P(L) - Price Range Lower Bound\n",
    " - P(1Day) - First Day Trading Price\n",
    " - C1 - Days\n",
    " - C2 - Top-Tier Dummy\n",
    " - C3 - Earnings per Share\n",
    " - C4 - Prior NASDAQ 15-Day Returns\n",
    " - C5 - Outstanding Shares\n",
    " - C6 - Offering Shares\n",
    " - C7 - Sales\n",
    " - T1 - Number of Sentences\n",
    " - T2 - Number of Words\n",
    " - T3 - Number of Real Words\n",
    " - T4 - Number of Long Sentences\n",
    " - T5 - Number of Long Words\n",
    " - S1 - Number of Positive Words\n",
    " - S2 - Number of Negative Words\n",
    " - S3 - Number of Uncertain Words\n",
    " - Y1 - Pre-IPO Price Revision\n",
    " - Y2 - Post-IPO Initial Return\n",
    " - C3' - Positive EPS Dummy\n",
    " - C5' - Share Overhang\n",
    " - C6' - Up Revision\n",
    " - I1 - Ticker\n",
    " - I2 - Company Name\n",
    " - I3 - Standard Industry Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding | Exploration ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle our data, we first imported the data into a dataframe a tried to examine the data through the JupyterLab interface. We realized that it would be easier to analyze the data through Excel, so that is what we decided to do our data exploration through.\n",
    "\n",
    "After the intial data exploration, we looked for missing values, and ways for us to impute the missing values. The I3 column was the first column that had missing data. We decided that we can manually impute the missing values, as they were readily available online through government websites.\n",
    "\n",
    "Fore the columns that needed numerical imputations, we decided to impute using the median, as there were some major skews for some of the columns.\n",
    "\n",
    "After that, we decided to create new column names for each column, as there were some columns that included parentheses that were a bit tough to use later in the notebooks. Then we exported the dataframe to a csv file for use in both of our pipelines.\n",
    "\n",
    "Here is the final csv file from our Data Understanding | Exploration: [Data Exploration|Understanding](./ReadyDF.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Skewness - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our 'MinMax_Pipeline', we fixed the skew at the **END** of the pipeline, in comparison to the 'Z-Score Pipeline' when we fixed the skew at the **BEGINNING** of our pipeline.\n",
    "\n",
    "For the 'MinMax_Pipeline' we only had to fix the skew of 1 column (C7), as Normalizing and Standardizing the data was very helpful in fixing skew. [Skew for MinMax_Pipeline](./Min_Max_Pipeline/Skew_MinMax.ipynb)\n",
    "\n",
    "For the 'Z-Score Pipeline', we had to play with finding the best fixes for skew based on how skewed each column was. The columns that required more skew were a bit tricky, as we could not get some of them any lower than they are shown on the notebook. [Skew for Z-Score Pipeline](./Z-Score_Pipeline/Skew_Z.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For handling outliers, in the pipeline using MinMax, we had to deal with the outliers first before doing anything else. In the Z-Score Pipeline, we had to deal with the Outliers **SECOND** after handling the skew.\n",
    "\n",
    "For handling outliers for the MinMax_Pipeline, we used IQR (Inter-Quartile Range) to being the outliers back towards the mean of the column. We used a function that we definted that would be used for each column with outliers. [Outliers for MinMax Pipeline](./Min_Max_Pipeline/Outliers_MinMax.ipynb)\n",
    "\n",
    "For handling the outliers with the Z-Score Pipeline, we used standard deviation to help with the outliers. We did have one outlier still appear on out of our box-and-whisker plots, but we believe that it is a visual error for the box-and-whisker plot.[Outliers for Z-Score Pipeline](./Z-Score_Pipeline/Outliers_Z.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For normalization for both pipelines, we normalized the MinMax Pipeline second, after fixing out outliers, and we normalized our Z-Score Pipeline at the end of all three steps.\n",
    "\n",
    "We used MinMax for normalizing the data in the MinMax Pipeline. [Normalization MinMax Pipeline](./Min_Max_Pipeline/Normalization(MinMax).ipynb)\n",
    "\n",
    "In the Z-Score Pipeline, we used the z-score for each column to normalize the data. [Normalization for Z-Score Pipeline](./Z-Score_Pipeline/Normalization_Z.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our correlation analysis, we had to concatinate the dataframes for each pipeline into one dataframe in order for the correlation matrix to show up on our notebooks.\n",
    "\n",
    "The conclusion that we came to is that we cannot use columns `C6'` when we run our models for `Y1`, as it is highly correlated.\n",
    "\n",
    "MinMax Pipeline Correlation: [Click Here](./Min_Max_Pipeline/Correlation_Analysis_MinMax.ipynb)\n",
    "\n",
    "Z-Score Pipeline Correlation: [Click Here](./Z-Score_Pipeline/Correlation_Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RFE in both pipelines, we could not use column `C6'`, as it was highly correlated with the columns `Y1`. We did use it for column `Y2` though.\n",
    "\n",
    "The models that we have run are at the bottom of each respective notebook. It gave us a general indication about why initial variables to use when running our models for the final step.\n",
    "\n",
    "RFE MinMax Pipeline: [Click Here](./Min_Max_Pipeline/RFE_MinMax.ipynb)\n",
    "\n",
    "RFE Z-Score Pipeline: [Click Here](./Z-Score_Pipeline/RFE_Z-Score.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Code - Both Pipelines ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the evaluation that we did was based on f1 and auc scores, that Dr. Tao provided a notebook for.\n",
    "\n",
    "For each notebook, we initially started with all of the variables when running the evaluation code, and then we would take a variable away, and see if the f1 and auc scores would improve or not. If they improved, we would leave out the features indefintely. If by taking out the feature made the scores worse, we would add back the feature, and then move onto taking out the next feature. This was our way of determining the best possible f1 and auc scores from our data.\n",
    "\n",
    "There is one caveat, as the f1 and auc scores did change each time that we ran the evaluation code, which was a bit worrisome, as our best model lost some points when we reran it a few times.\n",
    "\n",
    "Evaluation Code for MinMax Pipeline: [Click Here](./Min_Max_Pipeline/Evaluation-Code-Good-MinMax.ipynb)\n",
    "\n",
    "Evaluation Code for Z-Score Pipeline: [Click Here](./Z-Score_Pipeline/Evaluation-Code-Good-Z-Score.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
