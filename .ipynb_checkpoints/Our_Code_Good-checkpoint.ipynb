{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition 1 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question & Goal ####\n",
    "\n",
    "What are the determinants of the IPO underpricing phenomena? It is our job as a group to understand and identify the underlying determinants that factor into IPO underpricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding ###\n",
    "\n",
    "According to Investopedia.com, Underpricing is the listing of an intial public offering (IPO) below its market value. When the offer price of the stock is lower than the price of the first trade, the stock is considered to be underpriced. This will only last for a short amount of time, as the demand of the stock is going to drive it back up to its value.\n",
    "\n",
    "From a company standpoint, they wish to have the intial public offering as high as possible, which in turn raises the most capital. The quantitative factors that go into an initial public offering are all financial analysis reports from the company itself. Before the IPO, the company will be analyzed by its sales, expenses, earnings, and cash flow. Furthermore, a company's earnings and expected earnings growth are the biggest factors in the IPO. Marketability in a specific industry and the general market also can drive an IPO up or down.\n",
    "\n",
    "Once the investment bankers or IPO underwriters determine the IPO price of the company's stock, the day before the stock is offered publically, the company will market the IPO to potential investors. For historical purposes, IPOs are viewed as risky investments because of the lack of historical data that is collected on them. The less liquidity that the stock/company has and predicatble IPO shares are going to be, the more likely they are going to be underprices to compensate for assumed risk. Company's also underprice their IPO to entice more investors to buy stocks to raise more capital.\n",
    "\n",
    "With all of this information about intial public offerings, is there a few determinants that can be identified as to why the phenomenon of underpricing exists? The dataset that we have been provided provide information about companies and information regarding their IPO, such as IPO Offering, IPO Characteristics, Textual Characterisitics, Sentiment Characteristics, Target Variables, Control Variables, and IPO Identifiers.\n",
    "\n",
    "The variables that have been provided are listed below:\n",
    "\n",
    " - P(PHO) - Offer Price\n",
    " - P(H) - Price Range Higher Bound\n",
    " - P(L) - Price Range Lower Bound\n",
    " - P(1Day) - First Day Trading Price\n",
    " - C1 - Days\n",
    " - C2 - Top-Tier Dummy\n",
    " - C3 - Earnings per Share\n",
    " - C4 - Prior NASDAQ 15-Day Returns\n",
    " - C5 - Outstanding Shares\n",
    " - C6 - Offering Shares\n",
    " - C7 - Sales\n",
    " - T1 - Number of Sentences\n",
    " - T2 - Number of Words\n",
    " - T3 - Number of Real Words\n",
    " - T4 - Number of Long Sentences\n",
    " - T5 - Number of Long Words\n",
    " - S1 - Number of Positive Words\n",
    " - S2 - Number of Negative Words\n",
    " - S3 - Number of Uncertain Words\n",
    " - Y1 - Pre-IPO Price Revision\n",
    " - Y2 - Post-IPO Initial Return\n",
    " - C3' - Positive EPS Dummy\n",
    " - C5' - Share Overhang\n",
    " - C6' - Up Revision\n",
    " - I1 - Ticker\n",
    " - I2 - Company Name\n",
    " - I3 - Standard Industry Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the .xlsx datafile and converting into a DataFrame\n",
    "data = pd.read_excel(\"Competition1_raw_data.xlsx\",header=0,na_values='NaN')\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     I1                                  I2    I3 P(IPO) P(H) P(L) P(1Day)  \\\n",
      "0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674     10  9.5  8.5   11.87   \n",
      "1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834      8   10    8    7.25   \n",
      "2  ACAD          ACADIA PHARMACEUTICALS INC  2834      7   14   12     6.7   \n",
      "3  ACHN       ACHILLION PHARMACEUTICALS INC  2834   11.5   16   14   12.39   \n",
      "4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492     21   21   19    56.6   \n",
      "\n",
      "    C1 C2    C3 ...         C6       C7   T1     T2     T3   T4    T5  S1  \\\n",
      "0  122  1  3.43 ...   10600000   51.345  470  12719  11560  301   690  62   \n",
      "1  259  0 -1.62 ...    2400000   25.936  791  21792  19585  510  1120  71   \n",
      "2   90  1 -1.24 ...    5000000    7.378  201   5262   4785  128   325  61   \n",
      "3  209  1 -0.91 ...    4500000    8.526  328   8259   7574  177   509  80   \n",
      "4   80  1  0.07 ...    8250000  632.298  572  14830  13176  336   720  67   \n",
      "\n",
      "    S2   S3  \n",
      "0  117  139  \n",
      "1  242  237  \n",
      "2   33   60  \n",
      "3   59  110  \n",
      "4  149  167  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Understanding the datatypes for the features\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     I1                                  I2    I3 P_IPO  P_H  P_L P_1Day   C1  \\\n",
      "0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674    10  9.5  8.5  11.87  122   \n",
      "1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834     8   10    8   7.25  259   \n",
      "2  ACAD          ACADIA PHARMACEUTICALS INC  2834     7   14   12    6.7   90   \n",
      "3  ACHN       ACHILLION PHARMACEUTICALS INC  2834  11.5   16   14  12.39  209   \n",
      "4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492    21   21   19   56.6   80   \n",
      "\n",
      "  C2    C3 ...         C6       C7   T1     T2     T3   T4    T5  S1   S2   S3  \n",
      "0  1  3.43 ...   10600000   51.345  470  12719  11560  301   690  62  117  139  \n",
      "1  0 -1.62 ...    2400000   25.936  791  21792  19585  510  1120  71  242  237  \n",
      "2  1 -1.24 ...    5000000    7.378  201   5262   4785  128   325  61   33   60  \n",
      "3  1 -0.91 ...    4500000    8.526  328   8259   7574  177   509  80   59  110  \n",
      "4  1  0.07 ...    8250000  632.298  572  14830  13176  336   720  67  149  167  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Renaming Column Headers with '()' in it\n",
    "cols = ['I1','I2','I3','P_IPO','P_H','P_L','P_1Day','C1','C2','C3','C4','C5','C6','C7','T1','T2','T3','T4','T5','S1','S2','S3']\n",
    "\n",
    "# Define columns of 'df_data' using 'cols'\n",
    "df_data.columns = cols\n",
    "\n",
    "# Displaying the first 5 rows of dataframe 'df_data'\n",
    "# it should show 22 columns\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Missing Values ###\n",
    "\n",
    "Upon intial investigation, there seem to be no missing values, which is great.\n",
    "\n",
    "But doing some further digging, there are missing values, but the 'for loop', it does not pick up on dashes/hyphens. To show that there are missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1 0\n",
      "I2 0\n",
      "I3 0\n",
      "P(IPO) 0\n",
      "P(H) 0\n",
      "P(L) 0\n",
      "P(1Day) 0\n",
      "C1 0\n",
      "C2 0\n",
      "C3 0\n",
      "C4 0\n",
      "C5 0\n",
      "C6 0\n",
      "C7 0\n",
      "T1 0\n",
      "T2 0\n",
      "T3 0\n",
      "T4 0\n",
      "T5 0\n",
      "S1 0\n",
      "S2 0\n",
      "S3 0\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for column names\n",
    "names = []\n",
    "\n",
    "# Creating an empty list for the number of null values in each column\n",
    "values = []\n",
    "\n",
    "# Checking for Missing Values\n",
    "for col in df_data.columns:\n",
    "    names.append(col)\n",
    "    values.append(df_data[col].isnull().sum())\n",
    "    print(names[-1],values[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual Missing Values ####\n",
    "\n",
    "There is only one column `I1` that does not have any \"hyphens\" or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1 0\n",
      "I2 6\n",
      "I3 8\n",
      "P_IPO 5\n",
      "P_H 10\n",
      "P_L 10\n",
      "P_1Day 22\n",
      "C1 22\n",
      "C2 22\n",
      "C3 36\n",
      "C4 22\n",
      "C5 6\n",
      "C6 6\n",
      "C7 72\n",
      "T1 1\n",
      "T2 1\n",
      "T3 1\n",
      "T4 1\n",
      "T5 1\n",
      "S1 1\n",
      "S2 1\n",
      "S3 1\n"
     ]
    }
   ],
   "source": [
    "# Checking again to show missing values\n",
    "\n",
    "print(df_data.columns[0], df_data.I1.str.contains(r'-').sum())\n",
    "print(df_data.columns[1], df_data.I2.str.contains(r'-').sum())\n",
    "print(df_data.columns[2], df_data.I3.str.contains(r'-').sum())\n",
    "print(df_data.columns[3], df_data.P_IPO.str.contains(r'-').sum())\n",
    "print(df_data.columns[4], df_data.P_H.str.contains(r'-').sum())\n",
    "print(df_data.columns[5], df_data.P_L.str.contains(r'-').sum())\n",
    "print(df_data.columns[6], df_data.P_1Day.str.contains(r'-').sum())\n",
    "print(df_data.columns[7], df_data.C1.str.contains(r'-').sum())\n",
    "print(df_data.columns[8], df_data.C2.str.contains(r'-').sum())\n",
    "print(df_data.columns[9], df_data.C3.str.contains(r'-').sum())\n",
    "print(df_data.columns[10], df_data.C4.str.contains(r'-').sum())\n",
    "print(df_data.columns[11], df_data.C5.str.contains(r'-').sum())\n",
    "print(df_data.columns[12], df_data.C6.str.contains(r'-').sum())\n",
    "print(df_data.columns[13], df_data.C7.str.contains(r'-').sum())\n",
    "print(df_data.columns[14], df_data.T1.str.contains(r'-').sum())\n",
    "print(df_data.columns[15], df_data.T2.str.contains(r'-').sum())\n",
    "print(df_data.columns[16], df_data.T3.str.contains(r'-').sum())\n",
    "print(df_data.columns[17], df_data.T4.str.contains(r'-').sum())\n",
    "print(df_data.columns[18], df_data.T5.str.contains(r'-').sum())\n",
    "print(df_data.columns[19], df_data.S1.str.contains(r'-').sum())\n",
    "print(df_data.columns[20], df_data.S2.str.contains(r'-').sum())\n",
    "print(df_data.columns[21], df_data.S3.str.contains(r'-').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue that we have now is how to deal with these missing values.\n",
    "\n",
    "It is unique to see that columns `T1` through `S3` all have 1 missing value. Is it safe to assume that the individual missing values from those columns all belong to one record? Possibly. We will have to identify that one record if that is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>P_IPO</th>\n",
       "      <th>P_H</th>\n",
       "      <th>P_L</th>\n",
       "      <th>P_1Day</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>...</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>EURX</td>\n",
       "      <td>EURAND N.V.</td>\n",
       "      <td>2834</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>109.336</td>\n",
       "      <td>...</td>\n",
       "      <td>7000000</td>\n",
       "      <td>109.336</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       I1            I2    I3 P_IPO P_H P_L P_1Day C1 C2       C3 ...  \\\n",
       "217  EURX  EURAND N.V.   2834    16  19  17      -  -  -  109.336 ...   \n",
       "\n",
       "          C6       C7 T1 T2 T3 T4 T5 S1 S2 S3  \n",
       "217  7000000  109.336  -  -  -  -  -  -  -  -  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying the sole row that has missing data from features T1 through S3\n",
    "df_data.loc[df_data.T1 == '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the only row that has the columns `T1` through `S3` that are invalid. We will also identify all the rows that have missing data, which will help identify, overall, how many records have been recorded with at least 1 point of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-6070044c106e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_data\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot index with multidimensional key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "df_data.loc[df_data. == '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
