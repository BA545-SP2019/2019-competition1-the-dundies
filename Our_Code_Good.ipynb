{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition 1 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question & Goal ####\n",
    "\n",
    "What are the determinants of the IPO underpricing phenomena? It is our job as a group to understand and identify the underlying determinants that factor into IPO underpricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding ###\n",
    "\n",
    "According to Investopedia.com, Underpricing is the listing of an intial public offering (IPO) below its market value. When the offer price of the stock is lower than the price of the first trade, the stock is considered to be underpriced. This will only last for a short amount of time, as the demand of the stock is going to drive it back up to its value.\n",
    "\n",
    "From a company standpoint, they wish to have the intial public offering as high as possible, which in turn raises the most capital. The quantitative factors that go into an initial public offering are all financial analysis reports from the company itself. Before the IPO, the company will be analyzed by its sales, expenses, earnings, and cash flow. Furthermore, a company's earnings and expected earnings growth are the biggest factors in the IPO. Marketability in a specific industry and the general market also can drive an IPO up or down.\n",
    "\n",
    "Once the investment bankers or IPO underwriters determine the IPO price of the company's stock, the day before the stock is offered publically, the company will market the IPO to potential investors. For historical purposes, IPOs are viewed as risky investments because of the lack of historical data that is collected on them. The less liquidity that the stock/company has and predicatble IPO shares are going to be, the more likely they are going to be underprices to compensate for assumed risk. Company's also underprice their IPO to entice more investors to buy stocks to raise more capital.\n",
    "\n",
    "With all of this information about intial public offerings, is there a few determinants that can be identified as to why the phenomenon of underpricing exists? The dataset that we have been provided provide information about companies and information regarding their IPO, such as IPO Offering, IPO Characteristics, Textual Characterisitics, Sentiment Characteristics, Target Variables, Control Variables, and IPO Identifiers.\n",
    "\n",
    "The variables that have been provided are listed below:\n",
    "\n",
    " - P(PHO) - Offer Price\n",
    " - P(H) - Price Range Higher Bound\n",
    " - P(L) - Price Range Lower Bound\n",
    " - P(1Day) - First Day Trading Price\n",
    " - C1 - Days\n",
    " - C2 - Top-Tier Dummy\n",
    " - C3 - Earnings per Share\n",
    " - C4 - Prior NASDAQ 15-Day Returns\n",
    " - C5 - Outstanding Shares\n",
    " - C6 - Offering Shares\n",
    " - C7 - Sales\n",
    " - T1 - Number of Sentences\n",
    " - T2 - Number of Words\n",
    " - T3 - Number of Real Words\n",
    " - T4 - Number of Long Sentences\n",
    " - T5 - Number of Long Words\n",
    " - S1 - Number of Positive Words\n",
    " - S2 - Number of Negative Words\n",
    " - S3 - Number of Uncertain Words\n",
    " - Y1 - Pre-IPO Price Revision\n",
    " - Y2 - Post-IPO Initial Return\n",
    " - C3' - Positive EPS Dummy\n",
    " - C5' - Share Overhang\n",
    " - C6' - Up Revision\n",
    " - I1 - Ticker\n",
    " - I2 - Company Name\n",
    " - I3 - Standard Industry Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the .xlsx datafile and converting into a DataFrame\n",
    "data = pd.read_excel(\"Competition1_raw_data.xlsx\",header=0,na_values=\"-\")\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     I1                                  I2    I3  P(IPO)  P(H)  P(L)  \\\n",
      "0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674    10.0   9.5   8.5   \n",
      "1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834     8.0  10.0   8.0   \n",
      "2  ACAD          ACADIA PHARMACEUTICALS INC  2834     7.0  14.0  12.0   \n",
      "3  ACHN       ACHILLION PHARMACEUTICALS INC  2834    11.5  16.0  14.0   \n",
      "4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492    21.0  21.0  19.0   \n",
      "\n",
      "     P(1Day)     C1   C2    C3  ...            C6       C7     T1       T2  \\\n",
      "0  11.870000  122.0  1.0  3.43  ...    10600000.0   51.345  470.0  12719.0   \n",
      "1   7.250000  259.0  0.0 -1.62  ...     2400000.0   25.936  791.0  21792.0   \n",
      "2   6.700000   90.0  1.0 -1.24  ...     5000000.0    7.378  201.0   5262.0   \n",
      "3  12.390000  209.0  1.0 -0.91  ...     4500000.0    8.526  328.0   8259.0   \n",
      "4  56.599998   80.0  1.0  0.07  ...     8250000.0  632.298  572.0  14830.0   \n",
      "\n",
      "        T3     T4      T5    S1     S2     S3  \n",
      "0  11560.0  301.0   690.0  62.0  117.0  139.0  \n",
      "1  19585.0  510.0  1120.0  71.0  242.0  237.0  \n",
      "2   4785.0  128.0   325.0  61.0   33.0   60.0  \n",
      "3   7574.0  177.0   509.0  80.0   59.0  110.0  \n",
      "4  13176.0  336.0   720.0  67.0  149.0  167.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Understanding the datatypes for the features\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will remove the column headers that have parentheses in them to underscores, as it will be easier to reference those columns.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     I1                                  I2    I3  P_IPO   P_H   P_L  \\\n",
      "0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674   10.0   9.5   8.5   \n",
      "1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834    8.0  10.0   8.0   \n",
      "2  ACAD          ACADIA PHARMACEUTICALS INC  2834    7.0  14.0  12.0   \n",
      "3  ACHN       ACHILLION PHARMACEUTICALS INC  2834   11.5  16.0  14.0   \n",
      "4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492   21.0  21.0  19.0   \n",
      "\n",
      "      P_1Day     C1   C2    C3  ...            C6       C7     T1       T2  \\\n",
      "0  11.870000  122.0  1.0  3.43  ...    10600000.0   51.345  470.0  12719.0   \n",
      "1   7.250000  259.0  0.0 -1.62  ...     2400000.0   25.936  791.0  21792.0   \n",
      "2   6.700000   90.0  1.0 -1.24  ...     5000000.0    7.378  201.0   5262.0   \n",
      "3  12.390000  209.0  1.0 -0.91  ...     4500000.0    8.526  328.0   8259.0   \n",
      "4  56.599998   80.0  1.0  0.07  ...     8250000.0  632.298  572.0  14830.0   \n",
      "\n",
      "        T3     T4      T5    S1     S2     S3  \n",
      "0  11560.0  301.0   690.0  62.0  117.0  139.0  \n",
      "1  19585.0  510.0  1120.0  71.0  242.0  237.0  \n",
      "2   4785.0  128.0   325.0  61.0   33.0   60.0  \n",
      "3   7574.0  177.0   509.0  80.0   59.0  110.0  \n",
      "4  13176.0  336.0   720.0  67.0  149.0  167.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Renaming Column Headers with '()' in it\n",
    "cols = ['I1','I2','I3','P_IPO','P_H','P_L','P_1Day','C1','C2','C3','C4','C5','C6','C7','T1','T2','T3','T4','T5','S1','S2','S3']\n",
    "\n",
    "# Define columns of 'df_data' using 'cols'\n",
    "df_data.columns = cols\n",
    "\n",
    "# Displaying the first 5 rows of dataframe 'df_data'\n",
    "# it should show 22 columns\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1         object\n",
      "I2         object\n",
      "I3         object\n",
      "P_IPO     float64\n",
      "P_H       float64\n",
      "P_L       float64\n",
      "P_1Day    float64\n",
      "C1        float64\n",
      "C2        float64\n",
      "C3        float64\n",
      "C4        float64\n",
      "C5        float64\n",
      "C6        float64\n",
      "C7        float64\n",
      "T1        float64\n",
      "T2        float64\n",
      "T3        float64\n",
      "T4        float64\n",
      "T5        float64\n",
      "S1        float64\n",
      "S2        float64\n",
      "S3        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Defining the Data Types of the Data\n",
    "print(df_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            P_IPO         P_H         P_L       P_1Day           C1  \\\n",
      "count  677.000000  672.000000  672.000000   660.000000   660.000000   \n",
      "mean    13.837666   15.481190   13.515045    25.934766   149.728788   \n",
      "std      6.053731    6.653429    5.835646    73.234948   152.817467   \n",
      "min      3.000000    0.000000    3.000000     0.000000    10.000000   \n",
      "25%     10.000000   12.500000   11.000000    11.000000    85.000000   \n",
      "50%     13.500000   15.000000   13.000000    14.845000   107.000000   \n",
      "75%     17.000000   17.000000   15.000000    20.485000   155.250000   \n",
      "max     85.000000  135.000000  108.000000  1159.200562  2087.000000   \n",
      "\n",
      "               C2           C3          C4            C5            C6  \\\n",
      "count  660.000000   646.000000  660.000000  6.760000e+02  6.760000e+02   \n",
      "mean     0.859091     1.788904    0.007282  4.935776e+07  1.241519e+07   \n",
      "std      0.348192   162.666532    0.033318  1.043764e+08  2.512855e+07   \n",
      "min      0.000000  -786.239000   -0.162352  3.693227e+06  5.250000e+05   \n",
      "25%      1.000000    -0.852500   -0.013927  1.871417e+07  5.000000e+06   \n",
      "50%      1.000000     0.010000    0.009125  2.740018e+07  7.398704e+06   \n",
      "75%      1.000000     0.470000    0.031571  4.980786e+07  1.200000e+07   \n",
      "max      1.000000  3864.500000    0.092896  2.138085e+09  4.212336e+08   \n",
      "\n",
      "                 C7           T1            T2            T3           T4  \\\n",
      "count    610.000000   681.000000    681.000000    681.000000   681.000000   \n",
      "mean     500.459962   465.634361  12758.606461  11395.844347   294.353891   \n",
      "std     1648.337634   175.741647   5449.644597   4839.670179   121.532637   \n",
      "min        0.074000   132.000000      0.000000      0.000000     0.000000   \n",
      "25%       37.245750   351.000000   9195.000000   8162.000000   213.000000   \n",
      "50%      103.833000   444.000000  12045.000000  10785.000000   279.000000   \n",
      "75%      331.138000   551.000000  15241.000000  13760.000000   354.000000   \n",
      "max    30683.000000  1750.000000  49056.000000  43952.000000  1058.000000   \n",
      "\n",
      "                 T5          S1          S2          S3  \n",
      "count    681.000000  681.000000  681.000000  681.000000  \n",
      "mean     679.220264   68.421439  120.104258  144.759178  \n",
      "std      472.914323   39.096525   84.828959   69.276285  \n",
      "min       -1.000000   -1.000000   20.000000   26.000000  \n",
      "25%      462.000000   45.000000   73.000000  100.000000  \n",
      "50%      624.000000   60.000000  100.000000  134.000000  \n",
      "75%      795.000000   85.000000  142.000000  173.000000  \n",
      "max    10277.000000  309.000000  944.000000  883.000000  \n"
     ]
    }
   ],
   "source": [
    "# Describing the Data\n",
    "print(df_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Missing Values ###\n",
    "\n",
    "Upon intial investigation, there seem to be no missing values, which is great.\n",
    "\n",
    "But doing some further digging, there are missing values, but the 'for loop', it does not pick up on dashes/hyphens. To show that there are missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1 0\n",
      "I2 0\n",
      "I3 8\n",
      "P_IPO 5\n",
      "P_H 10\n",
      "P_L 10\n",
      "P_1Day 22\n",
      "C1 22\n",
      "C2 22\n",
      "C3 36\n",
      "C4 22\n",
      "C5 6\n",
      "C6 6\n",
      "C7 72\n",
      "T1 1\n",
      "T2 1\n",
      "T3 1\n",
      "T4 1\n",
      "T5 1\n",
      "S1 1\n",
      "S2 1\n",
      "S3 1\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for column names\n",
    "names = []\n",
    "\n",
    "# Creating an empty list for the number of null values in each column\n",
    "values = []\n",
    "\n",
    "# Checking for Missing Values\n",
    "for col in df_data.columns:\n",
    "    names.append(col)\n",
    "    values.append(df_data[col].isnull().sum())\n",
    "    print(names[-1],values[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual Missing Values ####\n",
    "\n",
    "There are only two columns `I1` and `I2` that do not have any \"hyphens\" or missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue that we have now is how to deal with these missing values.\n",
    "\n",
    "It is unique to see that columns `T1` through `S3` all have 1 missing value. Is it safe to assume that the individual missing values from those columns all belong to one record? Possibly. We will have to identify that one record if that is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1         object\n",
      "I2         object\n",
      "I3         object\n",
      "P_IPO     float64\n",
      "P_H       float64\n",
      "P_L       float64\n",
      "P_1Day    float64\n",
      "C1        float64\n",
      "C2        float64\n",
      "C3        float64\n",
      "C4        float64\n",
      "C5        float64\n",
      "C6        float64\n",
      "C7        float64\n",
      "T1        float64\n",
      "T2        float64\n",
      "T3        float64\n",
      "T4        float64\n",
      "T5        float64\n",
      "S1        float64\n",
      "S2        float64\n",
      "S3        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identifying the row that has the missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the only row that has the columns `T1` through `S3` that are invalid. We will also identify all the rows that have missing data, which will help identify, overall, how many records have been recorded with at least 1 point of missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
